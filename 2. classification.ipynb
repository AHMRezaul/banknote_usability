{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Pipeline Summary\n",
    "\n",
    "## 1. Datasets and Models Used\n",
    "   - **Datasets**:\n",
    "     - 4 datasets in total: three individual datasets and one combined dataset.\n",
    "   - **Models**:\n",
    "     - VGG16.\n",
    "     - ResNet50.\n",
    "     - EfficientNetB0.\n",
    "     - InceptionV3.\n",
    "\n",
    "## 2. Experiment Setup\n",
    "   - **Hyperparameter Ranges**:\n",
    "     - **Batch Size**: [16, 32, 64, 128].\n",
    "     - **Learning Rate**: [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005].\n",
    "     - **Epochs**: [15, 25, 35, 50].\n",
    "   - Selected optimal hyperparameters for each model based on validation performance.\n",
    "\n",
    "## 3. Training and Validation Process\n",
    "   - **Training Loop**:\n",
    "     - Optimized models over multiple epochs.\n",
    "     - Logged training and validation accuracy and loss per epoch.\n",
    "     - Tracked total training time for each model.\n",
    "   - **Validation**:\n",
    "     - Monitored model performance with validation data to track generalization and prevent overfitting.\n",
    "\n",
    "## 4. Evaluation Metrics and Visualizations\n",
    "   - **Test Set Evaluation**:\n",
    "     - Assessed model performance using the macro-averaged F1 score.\n",
    "     - Generated precision, recall, and F1 scores for each class.\n",
    "   - **Visualizations**:\n",
    "     - Confusion Matrix for class-wise prediction analysis.\n",
    "     - Classification Report Heatmap with precision, recall, and F1 scores.\n",
    "     - ROC Curves for multi-class AUC (Area Under the Curve) evaluation.\n",
    "\n",
    "## 5. Key Outputs for Dataset-Model Combination\n",
    "   - **Training and Validation Curves**:\n",
    "     - Generated and saved plots for training and validation accuracy and loss for each model-dataset pairing.\n",
    "   - **Model State Saving**:\n",
    "     - Saved trained model states for potential future use.\n",
    "   - **Detailed Metrics Visualization**:\n",
    "     - Produced visualizations including classification reports, confusion matrices, and ROC curves for comprehensive performance analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.9.9 (main, Mar 25 2022, 16:08:31) \n",
      "[GCC 10.3.0]\n",
      "NumPy Version: 1.21.4\n",
      "PyTorch Version: 1.12.1+cu113\n",
      "CUDA is available. PyTorch is using GPU.\n",
      "\n",
      "Number of GPUs available: 1\n",
      "\n",
      "GPU 0: NVIDIA A100-SXM4-80GB MIG 3g.40gb\n",
      "  Total Memory: 39.25 GB\n",
      "  Memory Allocated: 0.00 GB\n",
      "  Memory Reserved (Cached): 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Prints the installed versions of Python, NumPy, and PyTorch libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Function to check GPU availability and display memory statistics using PyTorch's CUDA interface\n",
    "def check_gpu_status():\n",
    "    # Check if GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA is available. PyTorch is using GPU.\\n\")\n",
    "        # Get the number of available GPUs\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Number of GPUs available: {num_gpus}\")\n",
    "        # Loop through each GPU and display its details\n",
    "        for gpu_id in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "            gpu_memory_allocated = torch.cuda.memory_allocated(gpu_id) / (1024 ** 3)  # In GB\n",
    "            gpu_memory_cached = torch.cuda.memory_reserved(gpu_id) / (1024 ** 3)      # In GB\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(gpu_id).total_memory / (1024 ** 3)  # In GB\n",
    "            print(f\"\\nGPU {gpu_id}: {gpu_name}\")\n",
    "            print(f\"  Total Memory: {gpu_memory_total:.2f} GB\")\n",
    "            print(f\"  Memory Allocated: {gpu_memory_allocated:.2f} GB\")\n",
    "            print(f\"  Memory Reserved (Cached): {gpu_memory_cached:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. PyTorch is using the CPU.\")\n",
    "\n",
    "# Run the GPU status check\n",
    "check_gpu_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">VGG16 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 12:04:52,334 - Training dataset size: 21802\n",
      "2024-11-12 12:04:52,335 - Validation dataset size: 2673\n",
      "2024-11-12 12:04:52,335 - Test dataset size: 2827\n",
      "2024-11-12 12:04:52,337 - Training with Batch Size: 64, Learning Rate: 1e-05, Epochs: 25\n",
      "2024-11-12 12:07:19,746 - Epoch 1/25 - Training: Loss = 1.7890, Accuracy = 0.3299\n",
      "2024-11-12 12:07:29,521 - Epoch 1/25 - Validation: Loss = 1.3709, Accuracy = 0.4860\n",
      "2024-11-12 12:07:29,523 - Time for epoch 1: 156.05s\n",
      "2024-11-12 12:09:26,261 - Epoch 2/25 - Training: Loss = 1.3098, Accuracy = 0.5333\n",
      "2024-11-12 12:09:33,155 - Epoch 2/25 - Validation: Loss = 1.2753, Accuracy = 0.5305\n",
      "2024-11-12 12:09:33,156 - Time for epoch 2: 123.63s\n",
      "2024-11-12 12:11:28,858 - Epoch 3/25 - Training: Loss = 1.0973, Accuracy = 0.6188\n",
      "2024-11-12 12:11:35,860 - Epoch 3/25 - Validation: Loss = 1.1293, Accuracy = 0.5918\n",
      "2024-11-12 12:11:35,861 - Time for epoch 3: 122.70s\n",
      "2024-11-12 12:13:31,750 - Epoch 4/25 - Training: Loss = 0.9202, Accuracy = 0.6799\n",
      "2024-11-12 12:13:38,341 - Epoch 4/25 - Validation: Loss = 0.8347, Accuracy = 0.7033\n",
      "2024-11-12 12:13:38,342 - Time for epoch 4: 122.48s\n",
      "2024-11-12 12:15:40,707 - Epoch 5/25 - Training: Loss = 0.7540, Accuracy = 0.7396\n",
      "2024-11-12 12:15:47,014 - Epoch 5/25 - Validation: Loss = 0.6561, Accuracy = 0.7748\n",
      "2024-11-12 12:15:47,015 - Time for epoch 5: 128.67s\n",
      "2024-11-12 12:17:51,969 - Epoch 6/25 - Training: Loss = 0.5887, Accuracy = 0.7985\n",
      "2024-11-12 12:17:58,438 - Epoch 6/25 - Validation: Loss = 0.5975, Accuracy = 0.7909\n",
      "2024-11-12 12:17:58,440 - Time for epoch 6: 131.42s\n",
      "2024-11-12 12:19:52,846 - Epoch 7/25 - Training: Loss = 0.4729, Accuracy = 0.8368\n",
      "2024-11-12 12:19:59,151 - Epoch 7/25 - Validation: Loss = 0.4736, Accuracy = 0.8257\n",
      "2024-11-12 12:19:59,153 - Time for epoch 7: 120.71s\n",
      "2024-11-12 12:21:53,436 - Epoch 8/25 - Training: Loss = 0.3794, Accuracy = 0.8703\n",
      "2024-11-12 12:21:59,402 - Epoch 8/25 - Validation: Loss = 0.3934, Accuracy = 0.8556\n",
      "2024-11-12 12:21:59,403 - Time for epoch 8: 120.25s\n",
      "2024-11-12 12:23:54,484 - Epoch 9/25 - Training: Loss = 0.3067, Accuracy = 0.8951\n",
      "2024-11-12 12:24:00,790 - Epoch 9/25 - Validation: Loss = 0.3973, Accuracy = 0.8646\n",
      "2024-11-12 12:24:00,791 - Time for epoch 9: 121.39s\n",
      "2024-11-12 12:25:55,449 - Epoch 10/25 - Training: Loss = 0.2545, Accuracy = 0.9120\n",
      "2024-11-12 12:26:01,428 - Epoch 10/25 - Validation: Loss = 0.3152, Accuracy = 0.8885\n",
      "2024-11-12 12:26:01,429 - Time for epoch 10: 120.64s\n",
      "2024-11-12 12:27:55,919 - Epoch 11/25 - Training: Loss = 0.2070, Accuracy = 0.9283\n",
      "2024-11-12 12:28:02,708 - Epoch 11/25 - Validation: Loss = 0.3715, Accuracy = 0.8795\n",
      "2024-11-12 12:28:02,709 - Time for epoch 11: 121.28s\n",
      "2024-11-12 12:29:58,548 - Epoch 12/25 - Training: Loss = 0.1771, Accuracy = 0.9407\n",
      "2024-11-12 12:30:04,564 - Epoch 12/25 - Validation: Loss = 0.3069, Accuracy = 0.9001\n",
      "2024-11-12 12:30:04,566 - Time for epoch 12: 121.85s\n",
      "2024-11-12 12:31:58,342 - Epoch 13/25 - Training: Loss = 0.1449, Accuracy = 0.9503\n",
      "2024-11-12 12:32:04,478 - Epoch 13/25 - Validation: Loss = 0.2910, Accuracy = 0.8997\n",
      "2024-11-12 12:32:04,479 - Time for epoch 13: 119.91s\n",
      "2024-11-12 12:34:06,391 - Epoch 14/25 - Training: Loss = 0.1223, Accuracy = 0.9585\n",
      "2024-11-12 12:34:14,152 - Epoch 14/25 - Validation: Loss = 0.2659, Accuracy = 0.9091\n",
      "2024-11-12 12:34:14,154 - Time for epoch 14: 129.67s\n",
      "2024-11-12 12:36:08,006 - Epoch 15/25 - Training: Loss = 0.1059, Accuracy = 0.9640\n",
      "2024-11-12 12:36:15,923 - Epoch 15/25 - Validation: Loss = 0.2324, Accuracy = 0.9285\n",
      "2024-11-12 12:36:15,924 - Time for epoch 15: 121.77s\n",
      "2024-11-12 12:38:13,727 - Epoch 16/25 - Training: Loss = 0.0914, Accuracy = 0.9675\n",
      "2024-11-12 12:38:21,632 - Epoch 16/25 - Validation: Loss = 0.2431, Accuracy = 0.9184\n",
      "2024-11-12 12:38:21,633 - Time for epoch 16: 125.71s\n",
      "2024-11-12 12:40:20,470 - Epoch 17/25 - Training: Loss = 0.0865, Accuracy = 0.9700\n",
      "2024-11-12 12:40:26,834 - Epoch 17/25 - Validation: Loss = 0.2549, Accuracy = 0.9140\n",
      "2024-11-12 12:40:26,835 - Time for epoch 17: 125.20s\n",
      "2024-11-12 12:42:26,076 - Epoch 18/25 - Training: Loss = 0.0615, Accuracy = 0.9803\n",
      "2024-11-12 12:42:32,298 - Epoch 18/25 - Validation: Loss = 0.1959, Accuracy = 0.9405\n",
      "2024-11-12 12:42:32,300 - Time for epoch 18: 125.46s\n",
      "2024-11-12 12:44:30,950 - Epoch 19/25 - Training: Loss = 0.0603, Accuracy = 0.9793\n",
      "2024-11-12 12:44:39,337 - Epoch 19/25 - Validation: Loss = 0.2493, Accuracy = 0.9308\n",
      "2024-11-12 12:44:39,338 - Time for epoch 19: 127.04s\n",
      "2024-11-12 12:46:36,546 - Epoch 20/25 - Training: Loss = 0.0564, Accuracy = 0.9802\n",
      "2024-11-12 12:46:43,567 - Epoch 20/25 - Validation: Loss = 0.1901, Accuracy = 0.9405\n",
      "2024-11-12 12:46:43,568 - Time for epoch 20: 124.23s\n",
      "2024-11-12 12:48:43,525 - Epoch 21/25 - Training: Loss = 0.0521, Accuracy = 0.9825\n",
      "2024-11-12 12:48:50,495 - Epoch 21/25 - Validation: Loss = 0.2396, Accuracy = 0.9353\n",
      "2024-11-12 12:48:50,496 - Time for epoch 21: 126.93s\n",
      "2024-11-12 12:50:48,056 - Epoch 22/25 - Training: Loss = 0.0472, Accuracy = 0.9857\n",
      "2024-11-12 12:50:54,154 - Epoch 22/25 - Validation: Loss = 0.2312, Accuracy = 0.9263\n",
      "2024-11-12 12:50:54,155 - Time for epoch 22: 123.66s\n",
      "2024-11-12 12:52:50,714 - Epoch 23/25 - Training: Loss = 0.0396, Accuracy = 0.9869\n",
      "2024-11-12 12:52:57,327 - Epoch 23/25 - Validation: Loss = 0.1677, Accuracy = 0.9484\n",
      "2024-11-12 12:52:57,328 - Time for epoch 23: 123.17s\n",
      "2024-11-12 12:54:55,433 - Epoch 24/25 - Training: Loss = 0.0420, Accuracy = 0.9864\n",
      "2024-11-12 12:55:01,833 - Epoch 24/25 - Validation: Loss = 0.1741, Accuracy = 0.9469\n",
      "2024-11-12 12:55:01,834 - Time for epoch 24: 124.50s\n",
      "2024-11-12 12:57:05,085 - Epoch 25/25 - Training: Loss = 0.0371, Accuracy = 0.9879\n",
      "2024-11-12 12:57:12,280 - Epoch 25/25 - Validation: Loss = 0.2136, Accuracy = 0.9342\n",
      "2024-11-12 12:57:12,281 - Time for epoch 25: 130.45s\n",
      "2024-11-12 12:57:12,282 - Total Training Time: 3138.77s\n",
      "2024-11-12 12:57:25,531 - Macro-Averaged F1 Score: 0.9315\n"
     ]
    }
   ],
   "source": [
    "# Image classification pipeline using VGG16\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.00001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.vgg16(weights=None)\n",
    "            model.classifier[6] = nn.Linear(model.classifier[6].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset VGG16 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_vgg16_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset VGG16 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_vgg16_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset VGG16 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_vgg16_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset VGG16 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_vgg16_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset VGG16 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_vgg16_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_vgg16_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">ResNet50 Model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 12:57:28,455 - Training dataset size: 21802\n",
      "2024-11-12 12:57:28,456 - Validation dataset size: 2673\n",
      "2024-11-12 12:57:28,456 - Test dataset size: 2827\n",
      "2024-11-12 12:57:28,458 - Training with Batch Size: 128, Learning Rate: 5e-05, Epochs: 25\n",
      "2024-11-12 12:58:41,925 - Epoch 1/25 - Training: Loss = 1.7063, Accuracy = 0.3695\n",
      "2024-11-12 12:58:46,768 - Epoch 1/25 - Validation: Loss = 1.6191, Accuracy = 0.4074\n",
      "2024-11-12 12:58:46,769 - Time for epoch 1: 78.09s\n",
      "2024-11-12 13:00:01,946 - Epoch 2/25 - Training: Loss = 1.2438, Accuracy = 0.5499\n",
      "2024-11-12 13:00:06,804 - Epoch 2/25 - Validation: Loss = 1.1753, Accuracy = 0.5769\n",
      "2024-11-12 13:00:06,806 - Time for epoch 2: 80.03s\n",
      "2024-11-12 13:01:20,467 - Epoch 3/25 - Training: Loss = 1.0146, Accuracy = 0.6399\n",
      "2024-11-12 13:01:25,215 - Epoch 3/25 - Validation: Loss = 0.9116, Accuracy = 0.6831\n",
      "2024-11-12 13:01:25,217 - Time for epoch 3: 78.41s\n",
      "2024-11-12 13:02:39,667 - Epoch 4/25 - Training: Loss = 0.8084, Accuracy = 0.7192\n",
      "2024-11-12 13:02:44,721 - Epoch 4/25 - Validation: Loss = 0.7757, Accuracy = 0.7273\n",
      "2024-11-12 13:02:44,722 - Time for epoch 4: 79.50s\n",
      "2024-11-12 13:04:00,113 - Epoch 5/25 - Training: Loss = 0.6308, Accuracy = 0.7780\n",
      "2024-11-12 13:04:04,869 - Epoch 5/25 - Validation: Loss = 0.6530, Accuracy = 0.7647\n",
      "2024-11-12 13:04:04,870 - Time for epoch 5: 80.15s\n",
      "2024-11-12 13:05:16,413 - Epoch 6/25 - Training: Loss = 0.4891, Accuracy = 0.8292\n",
      "2024-11-12 13:05:21,041 - Epoch 6/25 - Validation: Loss = 0.6046, Accuracy = 0.7770\n",
      "2024-11-12 13:05:21,041 - Time for epoch 6: 76.17s\n",
      "2024-11-12 13:06:38,499 - Epoch 7/25 - Training: Loss = 0.3814, Accuracy = 0.8679\n",
      "2024-11-12 13:06:44,035 - Epoch 7/25 - Validation: Loss = 0.4370, Accuracy = 0.8451\n",
      "2024-11-12 13:06:44,037 - Time for epoch 7: 82.99s\n",
      "2024-11-12 13:07:57,123 - Epoch 8/25 - Training: Loss = 0.2917, Accuracy = 0.8980\n",
      "2024-11-12 13:08:01,624 - Epoch 8/25 - Validation: Loss = 0.4530, Accuracy = 0.8511\n",
      "2024-11-12 13:08:01,624 - Time for epoch 8: 77.59s\n",
      "2024-11-12 13:09:23,563 - Epoch 9/25 - Training: Loss = 0.2312, Accuracy = 0.9217\n",
      "2024-11-12 13:09:28,253 - Epoch 9/25 - Validation: Loss = 0.4177, Accuracy = 0.8601\n",
      "2024-11-12 13:09:28,254 - Time for epoch 9: 86.63s\n",
      "2024-11-12 13:10:47,478 - Epoch 10/25 - Training: Loss = 0.1635, Accuracy = 0.9469\n",
      "2024-11-12 13:10:52,095 - Epoch 10/25 - Validation: Loss = 0.4233, Accuracy = 0.8605\n",
      "2024-11-12 13:10:52,096 - Time for epoch 10: 83.84s\n",
      "2024-11-12 13:12:05,418 - Epoch 11/25 - Training: Loss = 0.1207, Accuracy = 0.9606\n",
      "2024-11-12 13:12:12,439 - Epoch 11/25 - Validation: Loss = 0.3068, Accuracy = 0.9005\n",
      "2024-11-12 13:12:12,440 - Time for epoch 11: 80.34s\n",
      "2024-11-12 13:13:24,779 - Epoch 12/25 - Training: Loss = 0.0953, Accuracy = 0.9689\n",
      "2024-11-12 13:13:29,485 - Epoch 12/25 - Validation: Loss = 0.2662, Accuracy = 0.9080\n",
      "2024-11-12 13:13:29,486 - Time for epoch 12: 77.04s\n",
      "2024-11-12 13:14:46,682 - Epoch 13/25 - Training: Loss = 0.0777, Accuracy = 0.9749\n",
      "2024-11-12 13:14:52,402 - Epoch 13/25 - Validation: Loss = 0.2837, Accuracy = 0.9016\n",
      "2024-11-12 13:14:52,403 - Time for epoch 13: 82.92s\n",
      "2024-11-12 13:16:07,376 - Epoch 14/25 - Training: Loss = 0.0649, Accuracy = 0.9793\n",
      "2024-11-12 13:16:13,306 - Epoch 14/25 - Validation: Loss = 0.2621, Accuracy = 0.9241\n",
      "2024-11-12 13:16:13,307 - Time for epoch 14: 80.90s\n",
      "2024-11-12 13:17:27,812 - Epoch 15/25 - Training: Loss = 0.0484, Accuracy = 0.9847\n",
      "2024-11-12 13:17:32,749 - Epoch 15/25 - Validation: Loss = 0.2990, Accuracy = 0.9196\n",
      "2024-11-12 13:17:32,750 - Time for epoch 15: 79.44s\n",
      "2024-11-12 13:18:48,826 - Epoch 16/25 - Training: Loss = 0.0479, Accuracy = 0.9854\n",
      "2024-11-12 13:18:53,440 - Epoch 16/25 - Validation: Loss = 0.2346, Accuracy = 0.9252\n",
      "2024-11-12 13:18:53,441 - Time for epoch 16: 80.69s\n",
      "2024-11-12 13:20:06,502 - Epoch 17/25 - Training: Loss = 0.0433, Accuracy = 0.9867\n",
      "2024-11-12 13:20:11,388 - Epoch 17/25 - Validation: Loss = 0.2582, Accuracy = 0.9244\n",
      "2024-11-12 13:20:11,389 - Time for epoch 17: 77.95s\n",
      "2024-11-12 13:21:23,239 - Epoch 18/25 - Training: Loss = 0.0248, Accuracy = 0.9929\n",
      "2024-11-12 13:21:29,239 - Epoch 18/25 - Validation: Loss = 0.2925, Accuracy = 0.9192\n",
      "2024-11-12 13:21:29,241 - Time for epoch 18: 77.85s\n",
      "2024-11-12 13:22:42,820 - Epoch 19/25 - Training: Loss = 0.0257, Accuracy = 0.9925\n",
      "2024-11-12 13:22:47,420 - Epoch 19/25 - Validation: Loss = 0.2452, Accuracy = 0.9327\n",
      "2024-11-12 13:22:47,421 - Time for epoch 19: 78.18s\n",
      "2024-11-12 13:24:01,633 - Epoch 20/25 - Training: Loss = 0.0267, Accuracy = 0.9925\n",
      "2024-11-12 13:24:07,089 - Epoch 20/25 - Validation: Loss = 0.2910, Accuracy = 0.9188\n",
      "2024-11-12 13:24:07,090 - Time for epoch 20: 79.67s\n",
      "2024-11-12 13:25:18,143 - Epoch 21/25 - Training: Loss = 0.0347, Accuracy = 0.9890\n",
      "2024-11-12 13:25:22,682 - Epoch 21/25 - Validation: Loss = 0.2526, Accuracy = 0.9241\n",
      "2024-11-12 13:25:22,683 - Time for epoch 21: 75.59s\n",
      "2024-11-12 13:26:36,592 - Epoch 22/25 - Training: Loss = 0.0200, Accuracy = 0.9942\n",
      "2024-11-12 13:26:41,627 - Epoch 22/25 - Validation: Loss = 0.2249, Accuracy = 0.9420\n",
      "2024-11-12 13:26:41,628 - Time for epoch 22: 78.94s\n",
      "2024-11-12 13:27:51,266 - Epoch 23/25 - Training: Loss = 0.0220, Accuracy = 0.9936\n",
      "2024-11-12 13:27:55,873 - Epoch 23/25 - Validation: Loss = 0.2108, Accuracy = 0.9413\n",
      "2024-11-12 13:27:55,874 - Time for epoch 23: 74.24s\n",
      "2024-11-12 13:29:15,212 - Epoch 24/25 - Training: Loss = 0.0188, Accuracy = 0.9949\n",
      "2024-11-12 13:29:20,946 - Epoch 24/25 - Validation: Loss = 0.2372, Accuracy = 0.9371\n",
      "2024-11-12 13:29:20,948 - Time for epoch 24: 85.07s\n",
      "2024-11-12 13:30:35,131 - Epoch 25/25 - Training: Loss = 0.0266, Accuracy = 0.9924\n",
      "2024-11-12 13:30:40,286 - Epoch 25/25 - Validation: Loss = 0.2533, Accuracy = 0.9293\n",
      "2024-11-12 13:30:40,288 - Time for epoch 25: 79.34s\n",
      "2024-11-12 13:30:40,288 - Total Training Time: 1991.57s\n",
      "2024-11-12 13:30:48,750 - Macro-Averaged F1 Score: 0.9176\n"
     ]
    }
   ],
   "source": [
    "# Image classification pipeline using ResNet50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.00005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.resnet50(weights=None)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset ResNet50 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_resnet50_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset ResNet50 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_resnet50_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset ResNet50 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_resnet50_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset ResNet50 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_resnet50_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset ResNet50 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_resnet50_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_resnet50_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">EfficientNet_B0 Model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:30:51,127 - Training dataset size: 21802\n",
      "2024-11-12 13:30:51,128 - Validation dataset size: 2673\n",
      "2024-11-12 13:30:51,128 - Test dataset size: 2827\n",
      "2024-11-12 13:30:51,129 - Training with Batch Size: 128, Learning Rate: 5e-05, Epochs: 25\n",
      "2024-11-12 13:32:11,076 - Epoch 1/25 - Training: Loss = 2.1180, Accuracy = 0.2041\n",
      "2024-11-12 13:32:17,783 - Epoch 1/25 - Validation: Loss = 1.8279, Accuracy = 0.3008\n",
      "2024-11-12 13:32:17,785 - Time for epoch 1: 86.58s\n",
      "2024-11-12 13:33:28,487 - Epoch 2/25 - Training: Loss = 1.7019, Accuracy = 0.3564\n",
      "2024-11-12 13:33:32,934 - Epoch 2/25 - Validation: Loss = 1.5024, Accuracy = 0.4572\n",
      "2024-11-12 13:33:32,936 - Time for epoch 2: 75.15s\n",
      "2024-11-12 13:34:43,602 - Epoch 3/25 - Training: Loss = 1.3890, Accuracy = 0.4968\n",
      "2024-11-12 13:34:48,684 - Epoch 3/25 - Validation: Loss = 1.1935, Accuracy = 0.5630\n",
      "2024-11-12 13:34:48,686 - Time for epoch 3: 75.75s\n",
      "2024-11-12 13:35:58,734 - Epoch 4/25 - Training: Loss = 1.1630, Accuracy = 0.5865\n",
      "2024-11-12 13:36:03,992 - Epoch 4/25 - Validation: Loss = 1.0148, Accuracy = 0.6364\n",
      "2024-11-12 13:36:03,994 - Time for epoch 4: 75.31s\n",
      "2024-11-12 13:37:17,638 - Epoch 5/25 - Training: Loss = 1.0038, Accuracy = 0.6454\n",
      "2024-11-12 13:37:21,716 - Epoch 5/25 - Validation: Loss = 0.8564, Accuracy = 0.7030\n",
      "2024-11-12 13:37:21,717 - Time for epoch 5: 77.72s\n",
      "2024-11-12 13:38:34,221 - Epoch 6/25 - Training: Loss = 0.8645, Accuracy = 0.6951\n",
      "2024-11-12 13:38:39,248 - Epoch 6/25 - Validation: Loss = 0.8217, Accuracy = 0.7018\n",
      "2024-11-12 13:38:39,249 - Time for epoch 6: 77.53s\n",
      "2024-11-12 13:39:50,533 - Epoch 7/25 - Training: Loss = 0.7447, Accuracy = 0.7374\n",
      "2024-11-12 13:39:55,230 - Epoch 7/25 - Validation: Loss = 0.7186, Accuracy = 0.7422\n",
      "2024-11-12 13:39:55,231 - Time for epoch 7: 75.98s\n",
      "2024-11-12 13:41:06,793 - Epoch 8/25 - Training: Loss = 0.6331, Accuracy = 0.7810\n",
      "2024-11-12 13:41:11,152 - Epoch 8/25 - Validation: Loss = 0.6358, Accuracy = 0.7673\n",
      "2024-11-12 13:41:11,153 - Time for epoch 8: 75.92s\n",
      "2024-11-12 13:42:22,560 - Epoch 9/25 - Training: Loss = 0.5397, Accuracy = 0.8134\n",
      "2024-11-12 13:42:26,771 - Epoch 9/25 - Validation: Loss = 0.5474, Accuracy = 0.7987\n",
      "2024-11-12 13:42:26,773 - Time for epoch 9: 75.62s\n",
      "2024-11-12 13:43:40,437 - Epoch 10/25 - Training: Loss = 0.4643, Accuracy = 0.8382\n",
      "2024-11-12 13:43:46,339 - Epoch 10/25 - Validation: Loss = 0.4755, Accuracy = 0.8290\n",
      "2024-11-12 13:43:46,340 - Time for epoch 10: 79.57s\n",
      "2024-11-12 13:44:56,613 - Epoch 11/25 - Training: Loss = 0.3921, Accuracy = 0.8635\n",
      "2024-11-12 13:45:00,719 - Epoch 11/25 - Validation: Loss = 0.4116, Accuracy = 0.8537\n",
      "2024-11-12 13:45:00,720 - Time for epoch 11: 74.38s\n",
      "2024-11-12 13:46:14,442 - Epoch 12/25 - Training: Loss = 0.3561, Accuracy = 0.8782\n",
      "2024-11-12 13:46:18,604 - Epoch 12/25 - Validation: Loss = 0.3828, Accuracy = 0.8691\n",
      "2024-11-12 13:46:18,605 - Time for epoch 12: 77.88s\n",
      "2024-11-12 13:47:28,397 - Epoch 13/25 - Training: Loss = 0.3057, Accuracy = 0.8957\n",
      "2024-11-12 13:47:32,414 - Epoch 13/25 - Validation: Loss = 0.3220, Accuracy = 0.8833\n",
      "2024-11-12 13:47:32,414 - Time for epoch 13: 73.81s\n",
      "2024-11-12 13:48:44,160 - Epoch 14/25 - Training: Loss = 0.2693, Accuracy = 0.9073\n",
      "2024-11-12 13:48:48,706 - Epoch 14/25 - Validation: Loss = 0.3229, Accuracy = 0.8822\n",
      "2024-11-12 13:48:48,707 - Time for epoch 14: 76.29s\n",
      "2024-11-12 13:49:59,891 - Epoch 15/25 - Training: Loss = 0.2292, Accuracy = 0.9212\n",
      "2024-11-12 13:50:03,960 - Epoch 15/25 - Validation: Loss = 0.3278, Accuracy = 0.8881\n",
      "2024-11-12 13:50:03,961 - Time for epoch 15: 75.25s\n",
      "2024-11-12 13:51:18,042 - Epoch 16/25 - Training: Loss = 0.2098, Accuracy = 0.9301\n",
      "2024-11-12 13:51:22,267 - Epoch 16/25 - Validation: Loss = 0.2649, Accuracy = 0.9027\n",
      "2024-11-12 13:51:22,268 - Time for epoch 16: 78.31s\n",
      "2024-11-12 13:52:33,683 - Epoch 17/25 - Training: Loss = 0.1897, Accuracy = 0.9365\n",
      "2024-11-12 13:52:38,440 - Epoch 17/25 - Validation: Loss = 0.2758, Accuracy = 0.9042\n",
      "2024-11-12 13:52:38,441 - Time for epoch 17: 76.17s\n",
      "2024-11-12 13:53:49,332 - Epoch 18/25 - Training: Loss = 0.1690, Accuracy = 0.9420\n",
      "2024-11-12 13:53:54,368 - Epoch 18/25 - Validation: Loss = 0.2650, Accuracy = 0.9083\n",
      "2024-11-12 13:53:54,369 - Time for epoch 18: 75.93s\n",
      "2024-11-12 13:55:02,523 - Epoch 19/25 - Training: Loss = 0.1518, Accuracy = 0.9506\n",
      "2024-11-12 13:55:07,068 - Epoch 19/25 - Validation: Loss = 0.2307, Accuracy = 0.9211\n",
      "2024-11-12 13:55:07,070 - Time for epoch 19: 72.70s\n",
      "2024-11-12 13:56:15,463 - Epoch 20/25 - Training: Loss = 0.1401, Accuracy = 0.9530\n",
      "2024-11-12 13:56:20,436 - Epoch 20/25 - Validation: Loss = 0.2394, Accuracy = 0.9207\n",
      "2024-11-12 13:56:20,438 - Time for epoch 20: 73.37s\n",
      "2024-11-12 13:57:28,578 - Epoch 21/25 - Training: Loss = 0.1251, Accuracy = 0.9603\n",
      "2024-11-12 13:57:33,752 - Epoch 21/25 - Validation: Loss = 0.2163, Accuracy = 0.9327\n",
      "2024-11-12 13:57:33,753 - Time for epoch 21: 73.31s\n",
      "2024-11-12 13:58:44,185 - Epoch 22/25 - Training: Loss = 0.1133, Accuracy = 0.9622\n",
      "2024-11-12 13:58:48,303 - Epoch 22/25 - Validation: Loss = 0.2279, Accuracy = 0.9342\n",
      "2024-11-12 13:58:48,304 - Time for epoch 22: 74.55s\n",
      "2024-11-12 14:00:01,898 - Epoch 23/25 - Training: Loss = 0.1035, Accuracy = 0.9656\n",
      "2024-11-12 14:00:06,065 - Epoch 23/25 - Validation: Loss = 0.2362, Accuracy = 0.9274\n",
      "2024-11-12 14:00:06,066 - Time for epoch 23: 77.76s\n",
      "2024-11-12 14:01:14,625 - Epoch 24/25 - Training: Loss = 0.1007, Accuracy = 0.9667\n",
      "2024-11-12 14:01:19,327 - Epoch 24/25 - Validation: Loss = 0.1879, Accuracy = 0.9394\n",
      "2024-11-12 14:01:19,328 - Time for epoch 24: 73.26s\n",
      "2024-11-12 14:02:31,525 - Epoch 25/25 - Training: Loss = 0.0898, Accuracy = 0.9715\n",
      "2024-11-12 14:02:36,932 - Epoch 25/25 - Validation: Loss = 0.2341, Accuracy = 0.9312\n",
      "2024-11-12 14:02:36,933 - Time for epoch 25: 77.60s\n",
      "2024-11-12 14:02:36,933 - Total Training Time: 1905.69s\n",
      "2024-11-12 14:02:43,469 - Macro-Averaged F1 Score: 0.9417\n"
     ]
    }
   ],
   "source": [
    "# Image classification pipeline using EfficientNet-B0\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.00005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.efficientnet_b0(weights=None)\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset EfficientNet_B0 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_EfficientNet_B0_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset EfficientNet_B0 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_EfficientNet_B0_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset EfficientNet_B0 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_EfficientNet_B0_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset EfficientNet_B0 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_EfficientNet_B0_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset EfficientNet_B0 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_EfficientNet_B0_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_efficientnet_b0_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Inception_V3 Model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:02:45,680 - Training dataset size: 21802\n",
      "2024-11-12 14:02:45,681 - Validation dataset size: 2673\n",
      "2024-11-12 14:02:45,681 - Test dataset size: 2827\n",
      "2024-11-12 14:02:45,683 - Training with Batch Size: 64, Learning Rate: 0.0001, Epochs: 25\n",
      "2024-11-12 14:04:59,007 - Epoch 1/25 - Training: Loss = 1.4714, Accuracy = 0.4627\n",
      "2024-11-12 14:05:06,757 - Epoch 1/25 - Validation: Loss = 1.1926, Accuracy = 0.5593\n",
      "2024-11-12 14:05:06,758 - Time for epoch 1: 140.80s\n",
      "2024-11-12 14:07:12,590 - Epoch 2/25 - Training: Loss = 0.9756, Accuracy = 0.6521\n",
      "2024-11-12 14:07:20,260 - Epoch 2/25 - Validation: Loss = 0.8669, Accuracy = 0.6891\n",
      "2024-11-12 14:07:20,262 - Time for epoch 2: 133.50s\n",
      "2024-11-12 14:09:29,371 - Epoch 3/25 - Training: Loss = 0.7513, Accuracy = 0.7381\n",
      "2024-11-12 14:09:37,760 - Epoch 3/25 - Validation: Loss = 0.7306, Accuracy = 0.7235\n",
      "2024-11-12 14:09:37,761 - Time for epoch 3: 137.50s\n",
      "2024-11-12 14:11:46,736 - Epoch 4/25 - Training: Loss = 0.5979, Accuracy = 0.7914\n",
      "2024-11-12 14:11:54,399 - Epoch 4/25 - Validation: Loss = 0.6524, Accuracy = 0.7587\n",
      "2024-11-12 14:11:54,400 - Time for epoch 4: 136.64s\n",
      "2024-11-12 14:14:05,035 - Epoch 5/25 - Training: Loss = 0.4707, Accuracy = 0.8362\n",
      "2024-11-12 14:14:13,805 - Epoch 5/25 - Validation: Loss = 0.4882, Accuracy = 0.8328\n",
      "2024-11-12 14:14:13,807 - Time for epoch 5: 139.40s\n",
      "2024-11-12 14:16:21,728 - Epoch 6/25 - Training: Loss = 0.3816, Accuracy = 0.8672\n",
      "2024-11-12 14:16:30,220 - Epoch 6/25 - Validation: Loss = 0.4431, Accuracy = 0.8403\n",
      "2024-11-12 14:16:30,221 - Time for epoch 6: 136.41s\n",
      "2024-11-12 14:18:44,037 - Epoch 7/25 - Training: Loss = 0.3185, Accuracy = 0.8895\n",
      "2024-11-12 14:18:52,497 - Epoch 7/25 - Validation: Loss = 0.4499, Accuracy = 0.8485\n",
      "2024-11-12 14:18:52,499 - Time for epoch 7: 142.28s\n",
      "2024-11-12 14:21:00,006 - Epoch 8/25 - Training: Loss = 0.2484, Accuracy = 0.9136\n",
      "2024-11-12 14:21:07,953 - Epoch 8/25 - Validation: Loss = 0.4242, Accuracy = 0.8474\n",
      "2024-11-12 14:21:07,955 - Time for epoch 8: 135.45s\n",
      "2024-11-12 14:23:18,256 - Epoch 9/25 - Training: Loss = 0.2030, Accuracy = 0.9313\n",
      "2024-11-12 14:23:26,868 - Epoch 9/25 - Validation: Loss = 0.3236, Accuracy = 0.8893\n",
      "2024-11-12 14:23:26,869 - Time for epoch 9: 138.91s\n",
      "2024-11-12 14:25:45,967 - Epoch 10/25 - Training: Loss = 0.1696, Accuracy = 0.9436\n",
      "2024-11-12 14:25:54,833 - Epoch 10/25 - Validation: Loss = 0.3107, Accuracy = 0.9005\n",
      "2024-11-12 14:25:54,834 - Time for epoch 10: 147.96s\n",
      "2024-11-12 14:28:03,396 - Epoch 11/25 - Training: Loss = 0.1376, Accuracy = 0.9525\n",
      "2024-11-12 14:28:11,662 - Epoch 11/25 - Validation: Loss = 0.3549, Accuracy = 0.8889\n",
      "2024-11-12 14:28:11,664 - Time for epoch 11: 136.83s\n",
      "2024-11-12 14:30:22,825 - Epoch 12/25 - Training: Loss = 0.1160, Accuracy = 0.9600\n",
      "2024-11-12 14:30:31,062 - Epoch 12/25 - Validation: Loss = 0.3208, Accuracy = 0.9024\n",
      "2024-11-12 14:30:31,063 - Time for epoch 12: 139.40s\n",
      "2024-11-12 14:32:39,949 - Epoch 13/25 - Training: Loss = 0.1012, Accuracy = 0.9657\n",
      "2024-11-12 14:32:52,215 - Epoch 13/25 - Validation: Loss = 0.2572, Accuracy = 0.9192\n",
      "2024-11-12 14:32:52,217 - Time for epoch 13: 141.15s\n",
      "2024-11-12 14:35:02,853 - Epoch 14/25 - Training: Loss = 0.0836, Accuracy = 0.9715\n",
      "2024-11-12 14:35:10,958 - Epoch 14/25 - Validation: Loss = 0.2538, Accuracy = 0.9252\n",
      "2024-11-12 14:35:10,959 - Time for epoch 14: 138.74s\n",
      "2024-11-12 14:37:21,173 - Epoch 15/25 - Training: Loss = 0.0753, Accuracy = 0.9754\n",
      "2024-11-12 14:37:29,470 - Epoch 15/25 - Validation: Loss = 0.2413, Accuracy = 0.9214\n",
      "2024-11-12 14:37:29,471 - Time for epoch 15: 138.51s\n",
      "2024-11-12 14:39:40,940 - Epoch 16/25 - Training: Loss = 0.0681, Accuracy = 0.9773\n",
      "2024-11-12 14:39:49,326 - Epoch 16/25 - Validation: Loss = 0.2571, Accuracy = 0.9147\n",
      "2024-11-12 14:39:49,327 - Time for epoch 16: 139.85s\n",
      "2024-11-12 14:41:58,551 - Epoch 17/25 - Training: Loss = 0.0506, Accuracy = 0.9828\n",
      "2024-11-12 14:42:06,572 - Epoch 17/25 - Validation: Loss = 0.2086, Accuracy = 0.9405\n",
      "2024-11-12 14:42:06,573 - Time for epoch 17: 137.24s\n",
      "2024-11-12 14:44:16,878 - Epoch 18/25 - Training: Loss = 0.0551, Accuracy = 0.9820\n",
      "2024-11-12 14:44:25,881 - Epoch 18/25 - Validation: Loss = 0.2697, Accuracy = 0.9196\n",
      "2024-11-12 14:44:25,882 - Time for epoch 18: 139.31s\n",
      "2024-11-12 14:46:32,040 - Epoch 19/25 - Training: Loss = 0.0357, Accuracy = 0.9883\n",
      "2024-11-12 14:46:39,846 - Epoch 19/25 - Validation: Loss = 0.2090, Accuracy = 0.9330\n",
      "2024-11-12 14:46:39,848 - Time for epoch 19: 133.96s\n",
      "2024-11-12 14:48:46,907 - Epoch 20/25 - Training: Loss = 0.0449, Accuracy = 0.9852\n",
      "2024-11-12 14:48:56,047 - Epoch 20/25 - Validation: Loss = 0.1762, Accuracy = 0.9454\n",
      "2024-11-12 14:48:56,049 - Time for epoch 20: 136.20s\n",
      "2024-11-12 14:51:03,946 - Epoch 21/25 - Training: Loss = 0.0409, Accuracy = 0.9866\n",
      "2024-11-12 14:51:11,952 - Epoch 21/25 - Validation: Loss = 0.1756, Accuracy = 0.9461\n",
      "2024-11-12 14:51:11,953 - Time for epoch 21: 135.90s\n",
      "2024-11-12 14:53:22,888 - Epoch 22/25 - Training: Loss = 0.0306, Accuracy = 0.9899\n",
      "2024-11-12 14:53:31,783 - Epoch 22/25 - Validation: Loss = 0.1503, Accuracy = 0.9577\n",
      "2024-11-12 14:53:31,785 - Time for epoch 22: 139.83s\n",
      "2024-11-12 14:55:37,080 - Epoch 23/25 - Training: Loss = 0.0275, Accuracy = 0.9916\n",
      "2024-11-12 14:55:46,194 - Epoch 23/25 - Validation: Loss = 0.2304, Accuracy = 0.9379\n",
      "2024-11-12 14:55:46,195 - Time for epoch 23: 134.41s\n",
      "2024-11-12 14:57:55,259 - Epoch 24/25 - Training: Loss = 0.0340, Accuracy = 0.9891\n",
      "2024-11-12 14:58:02,958 - Epoch 24/25 - Validation: Loss = 0.2173, Accuracy = 0.9375\n",
      "2024-11-12 14:58:02,959 - Time for epoch 24: 136.76s\n",
      "2024-11-12 15:00:10,003 - Epoch 25/25 - Training: Loss = 0.0321, Accuracy = 0.9893\n",
      "2024-11-12 15:00:17,823 - Epoch 25/25 - Validation: Loss = 0.1738, Accuracy = 0.9566\n",
      "2024-11-12 15:00:17,825 - Time for epoch 25: 134.86s\n",
      "2024-11-12 15:00:17,825 - Total Training Time: 3451.82s\n",
      "2024-11-12 15:00:27,194 - Macro-Averaged F1 Score: 0.9519\n"
     ]
    }
   ],
   "source": [
    "# Image classification pipeline using InceptionV3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.0001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.inception_v3(weights=None, aux_logits=False, init_weights=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset Inception_V3 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_Inception_V3_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset Inception_V3 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_Inception_V3_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset Inception_V3 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_Inception_V3_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset Inception_V3 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_Inception_V3_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset Inception_V3 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_Inception_V3_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_inception_v3_model_trained.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
